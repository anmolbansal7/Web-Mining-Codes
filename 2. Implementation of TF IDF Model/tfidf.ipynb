{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35046d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anmol Bansal 19BCE0630\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc63eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"sample1.txt\", \"r\")\n",
    "f1 = f1.read()\n",
    "\n",
    "f2 = open(\"sample2.txt\", \"r\")\n",
    "f2 = f2.read()\n",
    "\n",
    "f3 = open(\"sample3.txt\", \"r\")\n",
    "f3 = f3.read()\n",
    "\n",
    "f4 = open(\"sample4.txt\", \"r\")\n",
    "f4 = f4.read()\n",
    "\n",
    "f5 = open(\"sample5.txt\", \"r\")\n",
    "f5 = f5.read()\n",
    "\n",
    "q = open(\"query.txt\", \"r\")\n",
    "q = q.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a49d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization: \n",
      "[['Web', 'mining', 'is', 'the', 'application', 'of', 'data', 'mining', 'techniques', 'to', 'discover', 'patterns', 'from', 'the', 'World', 'Wide', 'Web', '.'], ['Web', 'Mining', 'is', 'the', 'process', 'of', 'Data', 'Mining', 'techniques', 'to', 'automatically', 'discover', 'and', 'extract', 'information', 'from', 'Web', 'documents', 'and', 'services', '.'], ['Web', 'mining', 'can', 'widely', 'be', 'seen', 'as', 'the', 'application', 'of', 'adapted', 'data', 'mining', 'techniques', 'to', 'the', 'web', ',', 'whereas', 'data', 'mining', 'is', 'defined', 'as', 'the', 'application', 'of', 'the', 'algorithm', 'to', 'discover', 'patterns', 'on', 'mostly', 'structured', 'data', 'embedded', 'into', 'a', 'knowledge', 'discovery', 'process', '.'], ['Web', 'mining', 'is', 'the', 'process', 'of', 'using', 'data', 'mining', 'techniques', 'and', 'algorithms', 'to', 'extract', 'information', 'directly', 'from', 'the', 'Web', 'by', 'extracting', 'it', 'from', 'Web', 'documents', 'and', 'services', ',', 'Web', 'content', ',', 'hyperlinks', 'and', 'server', 'logs', '.'], ['Web', 'mining', 'can', 'widely', 'be', 'viewed', 'as', 'the', 'application', 'of', 'adapted', 'data', 'mining', 'methods', 'to', 'the', 'web', ',', 'whereas', 'data', 'mining', 'is', 'represented', 'as', 'the', 'application', 'of', 'the', 'algorithm', 'to', 'find', 'patterns', 'on', 'mostly', 'structured', 'data', 'fixed', 'into', 'a', 'knowledge', 'discovery', 'process', '.']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "tokens = []\n",
    "for i in [f1, f2, f3, f4, f5]:\n",
    "    t = word_tokenize(i)\n",
    "    tokens.append(t)\n",
    "\n",
    "print(\"Tokenization: \")\n",
    "print(tokens)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fb5fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Tokenization: \n",
      "['Web', 'Mining']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query Tokenization\n",
    "tQ = word_tokenize(q)\n",
    "\n",
    "print(\"Query Tokenization: \")\n",
    "print(tQ)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734e239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing: \n",
      "{'Web': 1, 'mining': 2, 'is': 3, 'the': 4, 'application': 5, 'of': 6, 'data': 7, 'techniques': 8, 'to': 9, 'discover': 10, 'patterns': 11, 'from': 12, 'World': 13, 'Wide': 14, '.': 15, 'Mining': 16, 'process': 17, 'Data': 18, 'automatically': 19, 'and': 20, 'extract': 21, 'information': 22, 'documents': 23, 'services': 24, 'can': 25, 'widely': 26, 'be': 27, 'seen': 28, 'as': 29, 'adapted': 30, 'web': 31, ',': 32, 'whereas': 33, 'defined': 34, 'algorithm': 35, 'on': 36, 'mostly': 37, 'structured': 38, 'embedded': 39, 'into': 40, 'a': 41, 'knowledge': 42, 'discovery': 43, 'using': 44, 'algorithms': 45, 'directly': 46, 'by': 47, 'extracting': 48, 'it': 49, 'content': 50, 'hyperlinks': 51, 'server': 52, 'logs': 53, 'viewed': 54, 'methods': 55, 'represented': 56, 'find': 57, 'fixed': 58}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Indexing\n",
    "index = {}\n",
    "count= 1\n",
    "for i in tokens:\n",
    "    for j in i:\n",
    "        if j not in index.keys():\n",
    "            index[j] = count\n",
    "            count+=1\n",
    "\n",
    "print(\"Indexing: \")\n",
    "print(index)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bfbf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: \n",
      "{'Web': [2, 2, 1, 4, 1], 'mining': [2, 0, 3, 2, 3], 'is': [1, 1, 1, 1, 1], 'the': [2, 1, 4, 2, 4], 'application': [1, 0, 2, 0, 2], 'of': [1, 1, 2, 1, 2], 'data': [1, 0, 3, 1, 3], 'techniques': [1, 1, 1, 1, 0], 'to': [1, 1, 2, 1, 2], 'discover': [1, 1, 1, 0, 0], 'patterns': [1, 0, 1, 0, 1], 'from': [1, 1, 0, 2, 0], 'World': [1, 0, 0, 0, 0], 'Wide': [1, 0, 0, 0, 0], '.': [1, 1, 1, 1, 1], 'Mining': [0, 2, 0, 0, 0], 'process': [0, 1, 1, 1, 1], 'Data': [0, 1, 0, 0, 0], 'automatically': [0, 1, 0, 0, 0], 'and': [0, 2, 0, 3, 0], 'extract': [0, 1, 0, 1, 0], 'information': [0, 1, 0, 1, 0], 'documents': [0, 1, 0, 1, 0], 'services': [0, 1, 0, 1, 0], 'can': [0, 0, 1, 0, 1], 'widely': [0, 0, 1, 0, 1], 'be': [0, 0, 1, 0, 1], 'seen': [0, 0, 1, 0, 0], 'as': [0, 0, 2, 0, 2], 'adapted': [0, 0, 1, 0, 1], 'web': [0, 0, 1, 0, 1], ',': [0, 0, 1, 2, 1], 'whereas': [0, 0, 1, 0, 1], 'defined': [0, 0, 1, 0, 0], 'algorithm': [0, 0, 1, 0, 1], 'on': [0, 0, 1, 0, 1], 'mostly': [0, 0, 1, 0, 1], 'structured': [0, 0, 1, 0, 1], 'embedded': [0, 0, 1, 0, 0], 'into': [0, 0, 1, 0, 1], 'a': [0, 0, 1, 0, 1], 'knowledge': [0, 0, 1, 0, 1], 'discovery': [0, 0, 1, 0, 1], 'using': [0, 0, 0, 1, 0], 'algorithms': [0, 0, 0, 1, 0], 'directly': [0, 0, 0, 1, 0], 'by': [0, 0, 0, 1, 0], 'extracting': [0, 0, 0, 1, 0], 'it': [0, 0, 0, 1, 0], 'content': [0, 0, 0, 1, 0], 'hyperlinks': [0, 0, 0, 1, 0], 'server': [0, 0, 0, 1, 0], 'logs': [0, 0, 0, 1, 0], 'viewed': [0, 0, 0, 0, 1], 'methods': [0, 0, 0, 0, 1], 'represented': [0, 0, 0, 0, 1], 'find': [0, 0, 0, 0, 1], 'fixed': [0, 0, 0, 0, 1]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Term Frequency Function\n",
    "def findTF(tokens, index):\n",
    "    tf = {}\n",
    "    for i in index.keys():\n",
    "        tf[i] = []\n",
    "        for j in tokens:\n",
    "            count = 0\n",
    "            for k in j:\n",
    "                if k==i:\n",
    "                    count+=1\n",
    "            tf[i].append(count)\n",
    "    return tf\n",
    "\n",
    "print(\"TF: \")\n",
    "print(findTF(tokens, index))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e5f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF: \n",
      "{'Web': 1.0, 'mining': 1.3219280948873624, 'is': 1.0, 'the': 1.0, 'application': 1.736965594166206, 'of': 1.0, 'data': 1.3219280948873624, 'techniques': 1.3219280948873624, 'to': 1.0, 'discover': 1.736965594166206, 'patterns': 1.736965594166206, 'from': 1.736965594166206, 'World': 3.321928094887362, 'Wide': 3.321928094887362, '.': 1.0, 'Mining': 3.321928094887362, 'process': 1.3219280948873624, 'Data': 3.321928094887362, 'automatically': 3.321928094887362, 'and': 2.3219280948873626, 'extract': 2.3219280948873626, 'information': 2.3219280948873626, 'documents': 2.3219280948873626, 'services': 2.3219280948873626, 'can': 2.3219280948873626, 'widely': 2.3219280948873626, 'be': 2.3219280948873626, 'seen': 3.321928094887362, 'as': 2.3219280948873626, 'adapted': 2.3219280948873626, 'web': 2.3219280948873626, ',': 1.736965594166206, 'whereas': 2.3219280948873626, 'defined': 3.321928094887362, 'algorithm': 2.3219280948873626, 'on': 2.3219280948873626, 'mostly': 2.3219280948873626, 'structured': 2.3219280948873626, 'embedded': 3.321928094887362, 'into': 2.3219280948873626, 'a': 2.3219280948873626, 'knowledge': 2.3219280948873626, 'discovery': 2.3219280948873626, 'using': 3.321928094887362, 'algorithms': 3.321928094887362, 'directly': 3.321928094887362, 'by': 3.321928094887362, 'extracting': 3.321928094887362, 'it': 3.321928094887362, 'content': 3.321928094887362, 'hyperlinks': 3.321928094887362, 'server': 3.321928094887362, 'logs': 3.321928094887362, 'viewed': 3.321928094887362, 'methods': 3.321928094887362, 'represented': 3.321928094887362, 'find': 3.321928094887362, 'fixed': 3.321928094887362}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inverse Document Frequency Function\n",
    "def findIDF(tokens, index):\n",
    "    tf = findTF(tokens, index)\n",
    "    temp = {}\n",
    "    n = len(tokens)\n",
    "    for i in tf.keys():\n",
    "        t = tf[i]\n",
    "        count = 0\n",
    "        for j in t:\n",
    "            if j>0:\n",
    "                count+=1\n",
    "        temp[i] = count\n",
    "    \n",
    "    idf = {}\n",
    "    for i in temp.keys():\n",
    "        idf[i] = 1 + math.log(n/temp[i], 2)\n",
    "    \n",
    "    return idf\n",
    "\n",
    "print(\"IDF: \")\n",
    "print(findIDF(tokens, index))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b37e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF*IDF for the tokens present in the Query\n",
    "def idfTF(tokens, index):\n",
    "    tf = findTF(tokens, index)\n",
    "    idf = findIDF(tokens, index)\n",
    "    tfidf = {}\n",
    "    n = len(tokens)\n",
    "    for i in tQ:\n",
    "        v = []\n",
    "        for j in range(0, n):\n",
    "            v.append(tf[i][j] * idf[i])\n",
    "        tfidf[i] = v\n",
    "            \n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45283b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF * IDF: \n",
      "{'Web': [2.0, 2.0, 1.0, 4.0, 1.0], 'Mining': [0.0, 6.643856189774724, 0.0, 0.0, 0.0]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TF * IDF: \")\n",
    "print(idfTF(tokens, index))   \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76080291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
